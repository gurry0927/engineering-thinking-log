# 多模態 Few-Shot：利用參考資料提升 Vision AI 準確度

## 📌 背景
在 P-04 門窗表辨識中，單純使用 Prompt 描述複雜的欄位規則往往不夠準確。我們發現透過提供具體範例（圖片 + JSON），能顯著提升解析效果。

## 🔍 技術名稱：多模態 In-Context Learning
這不是 RAG，因為沒有執行大規模檢索。這是一種 **Few-shot Vision Instruction** 策略：
- 將範例圖片與對應的標註 JSON 直接放入 Context。
- 模型在那一個會話中「學習」結構特徵與填寫標準。

## 💡 為什麼有效？
1. **模仿勝過理解**：大型模型對於「特定格式的模仿 (Mimicking)」能力極強。
2. **消除語義歧義**：文字說明「寬度」可能有多種解釋，但範例圖片標註出的 JSON 為模型定義了唯一的 **Ground Truth**。
3. **場景適配 (Task Specification)**：模型不需具備普世的建築知識，只需學會「我們公司這套報表的邏輯」。

## ⚠️ 風險：條件過擬合 (Conditional Overfitting)
- **現象**：模型開始「抄答案」，將範例中的數值應用到新問題上。
- **對策**：
  - **Prompt 隔離**：明確標註範例僅供參考結構，嚴禁複製數值。
  - **Fallback 設計**：要求模型在不確定時產出 `待確認`。
  - **樣本樣態多樣化**：提供 5-8 個不同格式的範例，打破單一 Pattern。

## 🚀 價值
這是一種**「零成本微調」**技術。我們不需花費昂貴的訓練費用，就能讓通用模型理解公司私有的格式，並達到產品級的準確率。

---
> **結語**：在 AI 工程中，「給模型一個好例子」的價值，有時超過寫一百行代碼。
