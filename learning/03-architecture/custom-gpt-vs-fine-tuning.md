# Custom GPT vs Fine-tuning：輕量化 AI 定製的選擇

## 📌 背景
在進行 P-07 專案時，需要將特定領域的解析邏輯固定下來。

## 🔍 技術層次對比

| 維度 | Custom GPT (封裝) | Fine-tuning (微調) |
| :--- | :--- | :--- |
| **改變什麼** | 行為流程、風格、參考知識 | 模型的底層權重與神經連結 |
| **生效速度** | 分鐘級（修改指令即生效） | 小時/天級（需準備訓練資料） |
| **資料要求** | 幾份範例文件、操作說明 | 數百至數千條標註數據 (JSONL) |
| **可維護性** | 高（隨時可改、重開即清空） | 低（重新訓練成本高） |
| **適用場景** | 欄位填寫、固定流程助理 | 特定語氣模仿、專業知識內化 |

## 💡 Custom GPT 的「偽微調」心法
Custom GPT 實際上是透過 **Instruction-level constraints** 來達成類似微調的效果。
- **Instruction**：設定思考框架與規則。
- **Knowledge Files**：提供 RAG (檢索增強生成) 基礎，讓模型有書可查。
- **Actions**：賦予模型與外部系統溝通的能力。

## ✅ 選用建議
對大部分開發者而言，**「Custom GPT」** 是最理想的起點。它容錯率高、迭代快，且能確保所有使用者在同一個「乾淨且受控」的環境下游走。

---
> **結論**：不要輕易動模型的大腦 (Fine-tune)，先試著給它一套好的 SOP 手冊 (Custom GPT)。
